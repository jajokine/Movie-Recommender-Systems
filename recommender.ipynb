{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Recommender Systems</h1>\n",
    "<h2 align='center'>with Neural Collaborative Filtering and Matrix Factorization</h2> \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='Images/movies.png' width="1100" height="400" />\n",
    "\n",
    "A Recommender System is a process that seeks to predict or filter user preferences according to the user's choices that are based on explicit (i.e. direct user interactions) and/or implicit feedback (i.e. indirect user interactions) from the user in order to provide recommendations what the user should do next. These choices are usually analyzed through methods such as clustering, nearest neighbor or matrix factorization, and the systems are widely being used in search queries in general, as well as various online products and services such as videos, movies, music, news, and books.\n",
    "\n",
    "The main idea is that we have a large database of users, but only a few of these people have actually given any explicit feedback from their interactions. This creates a database that is very sparse with insightful information and the key is to find a way to fill the missing entries either through feature engineering where we transform the explicit interactions into implicit ones, and hence create a different problem that is easier to solve or we try to fill the empty entries with different kinds of predictive methods.  \n",
    "\n",
    "We can break down the methods roughly into three categories where in the first, the recommendation is based solely on the features of items being used by the user which leads to the promotion of other items with similar features. This is the item-based filtering which relies on the descriptions of the item and the profile of the user's past preferences. Item-based recommenders are faster to deploy than user-based when the dataset is large. \n",
    "\n",
    "The second system is based on Collaborative Filtering (CF) which uses a combination of your past behavior and the experiences of other people in making the recommendation through an item or user based recommender system. These don't ncessary require features about the items or users to be known if the options available are diverse enough.  In the item-based, other users who browsed similar items will be recommended, and on the user based, items that similar users have browsed will be recommended. Both methods demand eventually a large pool of users from which the recommendation can be made, however data sparsity can affect the quality of user-based recommenders.\n",
    "\n",
    "The third category which is the one that is being used today, uses a combination of the previous systems, for example through low-rank matrix factorization that decomposes large matrices into compressed representation of the data with Singular Value Decomposition (SVD) or with deep learning systems through learned embeddings. The benefits of using the latest hybrid methods is that they are easier to scale to larger data sets and can better derive both tastes and preferences from the user patterns than the previous two, which rely heavily on the distances between the specific data points that are usually quite sparsely represented in large datasets, and hence, can lead to overfitting or just noisy representations of user tastes and preferences as there is just not enough information available. Once combined though, the methods can provide recommendations for items that the user hasn't seen or thought of before.\n",
    "\n",
    "In this notebook I will explore different hybrid methods that use implicit and explicit feedback from the ratings. For the Deep Learning models, I will be using PyTorch Lightning which is a recent PyTorch library that enables to scale training on multiple GPUs with no code changes and offers precoded boilerplates to speedup modeling for production. This makes the implementation of models quite easy and fun to do. \n",
    "\n",
    "The first method uses a Neural Colloborative Filtering (NCF) that captures the implicit feedback from positively and negatively labeled interactions through user and item embeddings inorder to make predictions what movies the user would like to see. This will be followed up by a model that uses explicit feedback from the ratings and which calculates the similarity of the embeddings with the product of the embeddings. We will then make some movie recommendations and compare the results to a more complicated model that again learns from the embeddings, but this time on its own without any added calculations. Finally, we will compare this results with a model that became famous through the Netflix prize competition and uses a completely different approach, namely a statistical technique that calculates predictions rather simply but very effectively from the entire dataset in a matter of seconds. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='800' height='400' src='Images/movies_3.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset comes from MovieLens project collected by GroupLens Research at the University of Minnesota. GroupLens have gathered datasets of movie ratings of various sizes ranging from 100,000 to all the way to 20,000,000. Each user has rated at least 20 movies which means we have enough information of all the users in order to analyze their preferences and make recommendations. In order to capture more recent films, I will be using a subset from the largest dataset that has 27,278 movies which were collected between 1995-2015 and published in 2016 (Research paper: http://files.grouplens.org/papers/harper-tiis2015.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant modules\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from itertools import zip_longest\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "# scipy\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# Pytorch & Pytorch Lightning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# configure\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27278, 3), (20000263, 4))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "\n",
    "movies_df = pd.read_csv('MovieLens/movie.csv', sep=',')\n",
    "ratings_df = pd.read_csv('MovieLens/rating.csv', sep=',', parse_dates=['timestamp'])\n",
    "movies_df.shape, ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating           timestamp\n",
       "0       1        2     3.5 2005-04-02 23:53:47\n",
       "1       1       29     3.5 2005-04-02 23:31:16\n",
       "2       1       32     3.5 2005-04-02 23:33:39\n",
       "3       1       47     3.5 2005-04-02 23:32:07\n",
       "4       1       50     3.5 2005-04-02 23:29:40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138493 unique users in the database\n"
     ]
    }
   ],
   "source": [
    "print('There are {} unique users in the database'.format(len(ratings_df['userId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26744 unique movies in the database\n"
     ]
    }
   ],
   "source": [
    "print('There are {} unique movies in the database'.format(len(ratings_df['movieId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    5561926\n",
       "3.0    4291193\n",
       "5.0    2898660\n",
       "3.5    2200156\n",
       "4.5    1534824\n",
       "2.0    1430997\n",
       "2.5     883398\n",
       "1.0     680732\n",
       "1.5     279252\n",
       "0.5     239125\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the ratings the average is 3.5255285642993797 and the median is 3.5\n"
     ]
    }
   ],
   "source": [
    "print('From the ratings the average is {} and the median is {}'.format(ratings_df[['userId','rating']].mean()[1], ratings_df[['userId', 'rating']].median()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 138493 people who have given a rating for 26744 movies and most have given a rating of 3 or more out of 5 which indicates most of the movies are either quite good or the people who rate the movies have a bias of giving a good rating rather than a bad one. This should be also accounted when modeling either by normalizing the ratings or by adding a bias term to the users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>32</th>\n",
       "      <th>50</th>\n",
       "      <th>110</th>\n",
       "      <th>150</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>457</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>780</th>\n",
       "      <th>1196</th>\n",
       "      <th>1210</th>\n",
       "      <th>2571</th>\n",
       "      <th>2858</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8405</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34576</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46470</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59477</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63147</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71975</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74142</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79159</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82418</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83090</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88820</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92011</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118205</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121535</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125794</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130767</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131904</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1     32    50    110   150   260   296   318   356   457   480   \\\n",
       "userId                                                                      \n",
       "8405      5.0   4.0   4.5   4.0   4.0   5.0   5.0   4.5   4.5   4.5   4.0   \n",
       "8963      2.5   3.5   3.5   2.0   3.5   5.0   3.0   3.5   3.5   5.0   2.0   \n",
       "15617     NaN   4.5   3.5   4.5   4.0   3.5   4.0   4.0   4.0   4.0   2.5   \n",
       "20132     5.0   4.0   5.0   1.0   4.0   4.0   4.0   5.0   4.0   5.0   NaN   \n",
       "34576     4.0   4.0   4.0   4.0   3.5   4.0   4.5   4.0   3.5   3.5   4.0   \n",
       "46470     5.0   4.5   3.0   5.0   4.0   5.0   4.0   5.0   5.0   3.0   2.5   \n",
       "59477     4.5   3.5   4.5   4.5   2.5   4.0   5.0   4.5   4.0   2.5   4.0   \n",
       "63147     4.5   4.0   2.5   3.0   4.0   3.5   4.5   2.5   NaN   3.0   NaN   \n",
       "71975     4.5   4.0   5.0   3.5   4.0   4.5   4.5   4.0   4.5   3.5   4.5   \n",
       "74142     5.0   5.0   5.0   3.0   3.0   5.0   5.0   5.0   2.0   1.0   2.5   \n",
       "79159     4.5   4.5   4.5   4.0   3.5   5.0   4.5   4.5   4.0   4.5   4.0   \n",
       "82418     5.0   5.0   5.0   1.0   4.0   5.0   5.0   5.0   4.0   4.0   4.0   \n",
       "83090     3.0   4.0   5.0   4.0   4.0   3.0   4.0   4.0   3.0   4.0   4.0   \n",
       "88820     4.0   4.0   4.0   4.5   5.0   5.0   5.0   5.0   5.0   5.0   4.0   \n",
       "92011     4.0   4.0   4.0   5.0   4.0   5.0   4.0   4.0   4.0   4.0   3.0   \n",
       "118205    4.0   4.0   4.5   5.0   4.0   4.0   4.5   4.0   4.0   4.0   3.0   \n",
       "121535    3.0   3.0   4.0   4.0   3.0   3.0   4.0   4.0   4.0   3.0   4.0   \n",
       "125794    5.0   4.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   \n",
       "130767    4.5   4.0   3.5   NaN   4.0   3.5   4.5   NaN   NaN   NaN   NaN   \n",
       "131904    3.0   4.0   4.0   4.0   NaN   4.0   4.0   4.5   3.0   3.5   4.0   \n",
       "\n",
       "movieId  527   589   592   593   780   1196  1210  2571  2858  \n",
       "userId                                                         \n",
       "8405      5.0   5.0   4.5   5.0   3.0   5.0   4.0   5.0   4.5  \n",
       "8963      4.0   3.0   2.0   5.0   3.0   5.0   3.0   2.5   4.5  \n",
       "15617     4.0   4.0   3.5   4.0   3.5   3.5   NaN   5.0   3.5  \n",
       "20132     5.0   4.0   5.0   5.0   4.0   4.0   4.0   4.0   5.0  \n",
       "34576     4.0   4.0   3.5   4.5   3.0   4.0   4.0   4.0   5.0  \n",
       "46470     2.5   3.0   5.0   3.5   4.5   4.0   5.0   5.0   3.5  \n",
       "59477     4.5   5.0   4.5   3.5   3.5   4.0   3.5   3.5   4.0  \n",
       "63147     4.5   2.5   NaN   2.0   2.5   4.5   NaN   3.0   2.5  \n",
       "71975     4.0   5.0   4.0   5.0   4.0   5.0   5.0   4.5   5.0  \n",
       "74142     5.0   3.0   4.0   2.0   3.0   5.0   3.0   5.0   3.0  \n",
       "79159     4.0   4.5   4.5   4.5   4.0   5.0   4.5   5.0   4.5  \n",
       "82418     5.0   4.0   5.0   5.0   4.0   5.0   5.0   5.0   5.0  \n",
       "83090     4.0   4.0   3.0   4.0   3.0   3.0   3.0   5.0   3.0  \n",
       "88820     5.0   4.5   4.0   5.0   2.5   5.0   5.0   5.0   4.0  \n",
       "92011     5.0   4.0   4.0   4.0   3.0   4.0   4.0   5.0   5.0  \n",
       "118205    4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0  \n",
       "121535    4.0   4.0   3.5   4.5   3.0   2.5   3.0   4.0   4.0  \n",
       "125794    5.0   5.0   4.0   5.0   4.0   5.0   4.0   5.0   5.0  \n",
       "130767    4.0   4.0   NaN   4.0   2.5   NaN   NaN   3.5   2.5  \n",
       "131904    4.0   4.0   3.0   4.0   3.5   4.0   4.0   4.5   3.5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_tab(ratings, n=20):\n",
    "    \"\"\"Cross-tabular view of users and movie ratings.\n",
    "    \"\"\"\n",
    "    users = ratings_df.groupby('userId')['rating'].count()\n",
    "    user_group = users.sort_values(ascending=False)[:20]\n",
    "    \n",
    "    movies = ratings_df.groupby('movieId')['rating'].count()\n",
    "    movie_group = movies.sort_values(ascending=False)[:20]\n",
    "    \n",
    "    matrix = (\n",
    "            ratings_df.join(user_group, rsuffix='_r', how='inner', on='userId').\n",
    "                    join(movie_group, rsuffix='_r', how='inner', on='movieId'))\n",
    "    \n",
    "    return pd.crosstab(matrix.userId, matrix.movieId, matrix.rating, aggfunc=np.sum)\n",
    "\n",
    "cross_tab(ratings_df, movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings database doesn't have any missing values, but once we create a user-item matrix of all the users together with all the movie ratings, we see that differences start to arise from those users that have rated many movies to those that haven't rated so many. These missing 'NaN' entries will need to be filled with an algorithm. We will begin to experminent with different models first starting with Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering via Implicit User Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset includes 20M recommendations from around 140,000 different users, but we will only need a portion of this to actually test the models so we will pick randomly 30 % of the users and their ratings for the recommendation systems and merge the two datasets into one for easier access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 6048287 ratings from 41547 users.\n"
     ]
    }
   ],
   "source": [
    "# Selecting 30 % of users and their ratings from the dataset\n",
    "\n",
    "rand_userIds = np.random.choice(ratings_df['userId'].unique(), size=int(len(ratings_df['userId'].unique())*0.3), replace=False)\n",
    "ratings = ratings_df.loc[ratings_df['userId'].isin(rand_userIds)]\n",
    "print('The dataset has {} ratings from {} users.'.format(len(ratings), len(rand_userIds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from the data\n",
    "\n",
    "As the data has a timestamp column that shows the date and time the review was submitted, we can use the most recent review from a user as the testing data and the reviews before that as the training data. This leave-one-out methodology is often used when training and evaluating recommender systems as this way we don't introduce possible data leakage with a look-ahead bias due to randomly splitting the data in a way that the most recent reviews could be used as training to evaluate the reviews of the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6006740, 3), (41547, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave-one-out train-test-split\n",
    "\n",
    "ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'] != 1] \n",
    "test_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "\n",
    "train_ratings = train_ratings[['userId', 'movieId', 'rating']] \n",
    "test_ratings = test_ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "train_ratings.shape, test_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model will use implicit feedback se first we need to reformulate what the rating actually stands for. The rating represents at the moment direct feedback from a movie and this needs to be made implicit by changing the rating from a qualitative description to a quantitative description which can be done by binarizing the rating into whether the user has seen the movie (i.e. rated the movie) or not. Hence, one will indicate the positive class that the user has seen the movie and zero the opposite. By making this change, the prediction also changes from trying to predict a movie rating into predicting whether the user will go see the movie. Whether someone will buy or click something is perhaps more important for businesses than whether they actually liked what they bought or clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2       1\n",
       "1       1       29       1\n",
       "2       1       32       1\n",
       "3       1       47       1\n",
       "4       1       50       1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing ratings into binary form\n",
    "\n",
    "train_ratings.loc[:, 'rating'] = 1\n",
    "test_ratings.loc[:, 'rating'] = 1\n",
    "\n",
    "train_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings now include only positive classes so next we need to make negative classes to indicate movies which the user would not be interested in seeing. This can be arbitrary, as we don't really know the exact number of movies or even the movies that the user doesn't like, but we could assume that it is more rare to find a very good movie than an average or even a bad one. \n",
    "\n",
    "So if we take a random collection of 5 movies for example, there should be a high chance that there is only one or a few that we actually like and the rest we are not that interested of. If you think of going to a movie theater that shows a dozen different movies, we could think that we would be interested of only a few of them, or in the case of a streaming service that offers a wide collection of different movies, once we start scrolling down the catalogue we find ourselves picking only a few of them, as both options often try to capture a variety of different types of movies for a variety of different types of people.\n",
    "\n",
    "Taking these considerations into account, we will create a ratio of 4:1, as in one movie seen means that there will be 4 other movies that we are not interested of seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensImplicitTrainDataset(Dataset):\n",
    "    \"\"\"Creates MovieLens PyTorch Dataset for Training\n",
    "    \n",
    "    Args:\n",
    "        ratings : Dataframe containing the movie ratings\n",
    "        all_movieIds: List containing all unique movieIds\n",
    "    \n",
    "    Returns:\n",
    "        torch tensors of users, items and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings, all_movieIds):\n",
    "        self.users, self.items, self.labels = self.get_train_dataset(ratings, all_movieIds)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "    \n",
    "    def get_train_dataset(self, ratings, all_movieIds):\n",
    "        # placeholders for the training set\n",
    "        users, items, labels = [], [], [] \n",
    "        # set of items the user has interacted with\n",
    "        user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId'])) # user interactions\n",
    "        \n",
    "        num_negatives = 4 # 4:1 ratio\n",
    "        \n",
    "        for (u, i) in tqdm(user_item_set):\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1) # interacted items for the user are positive\n",
    "            \n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_movieIds) # random selection\n",
    "                # check that user has not interacted with the item\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0) # not iteracted items for the user are negative\n",
    "                \n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensImplicitTestDataset(Dataset):\n",
    "    \"\"\"Creates MovieLens PyTorch Dataset for Testing\n",
    "    \n",
    "    Args:\n",
    "        ratings : Dataframe containing the movie ratings\n",
    "        all_movieIds: List containing all unique movieIds\n",
    "    \n",
    "    Returns:\n",
    "        torch tensors of users, items and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings, all_movieIds):\n",
    "        self.users, self.items, self.labels = self.get_test_dataset(ratings, all_movieIds)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "    \n",
    "    def get_test_dataset(self, ratings, all_movieIds):\n",
    "        # placeholders for the training set\n",
    "        users, items, labels = [], [], [] \n",
    "        # set of items the user has interacted with\n",
    "        user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId'])) # user interactions\n",
    "        \n",
    "        num_negatives = 4 # 4:1 ratio\n",
    "        \n",
    "        for (u, i) in tqdm(user_item_set):\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1) # interacted items for the user are positive\n",
    "            \n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_movieIds) # random selection\n",
    "                # check that user has not interacted with the item\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0) # not iteracted items for the user are negative\n",
    "                \n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering\n",
    "\n",
    "In order to capture the user preferences through Collaborative Filtering, we will use user and item embeddings which capture the user preferences from a high-dimensional vector space into a low-dimensional vector space. \n",
    "\n",
    "This way, the users with similar taste in movies should also have similar embeddings. The user embeddings show how the user has interacted with the movies and the item embeddings show how the other users have interacted with the movies, creating eventually collectively the user preferences. The more dimensions you use in the embeddings, the more complex the model becomes so the key will be to learn these embeddings in a straightforward and simple way that enables generalization without the risk of overfitting the data.\n",
    "\n",
    "As this is now a binary classification problem, the loss function will be the Binary Cross Entropy (BCE) that measures the cross entropy loss between the binary valued target and the input probabilities, and the calculations of the loss will be performed with the Adam optimizer which is a stochastic gradient descent method to calculate the gradients of the loss function.\n",
    "\n",
    "The inputs to the model are one-hot encoded user and item vectors which are then forwarded to the user and item embedding layers before concatenating together through two fully connected layers. The output layer has a Sigmoid function inorder to determine the most probable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class for the model\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\"Neural Collaborative Filtering (NCF) model with 8-dimensional embeddings\n",
    "    \n",
    "    research paper: Xiangnan He, Lizi Liao, Hanwang Zhang,\n",
    "    Liqiang Nie, Xia Hu, Tat-Seng Chua, (2017),\n",
    "    \"Neural Collaborative Filtering\", arXiv:1708.05031. \n",
    "    \n",
    "    Two embedding layers of dimension 8 lead to two fully connected layers of\n",
    "    16 and 64 parameters. Prediction with the Sigmoid function that forces\n",
    "    values to be between 0 and 1.\n",
    "    \n",
    "    Args:\n",
    "        num_users: Number of unique users (int)\n",
    "        num_items: Number of unique movies (int)\n",
    "        ratings: Dataframe containing the movie ratings for training\n",
    "        all_movieIds: List containing all unique movieIds (train+test)\n",
    "    \n",
    "    Returns:\n",
    "        predicted labels (0 or 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, train_ratings, test_ratings, all_movieIds):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.train_ratings = train_ratings\n",
    "        self.test_ratings = test_ratings\n",
    "        self.all_movieIds = all_movieIds\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "        \n",
    "        x = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        \n",
    "        prediction = nn.Sigmoid()(self.output(x))\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = self.loss(predicted_labels, labels.view(-1,1).float())\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        test_users, test_items, test_ratings = test_batch\n",
    "        test_pred = self(test_users, test_items)\n",
    "        loss = self.loss(test_pred, test_ratings.view(-1, 1).float())\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {'test_loss':loss, 'test_users': test_users.detach(), 'test_items': test_items.detach(), 'test_pred': test_pred.detach(), 'test_ratings': test_ratings.detach()}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensImplicitTrainDataset(self.train_ratings, self.all_movieIds), batch_size=512)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(MovieLensImplicitTestDataset(self.test_ratings, self.all_movieIds), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCF(\n",
       "  (user_embedding): Embedding(138491, 8)\n",
       "  (item_embedding): Embedding(131171, 8)\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model\n",
    "\n",
    "tb_logger = TensorBoardLogger('tb_logger', name='NeuralCollaborativeFiltering')\n",
    "\n",
    "num_users = ratings['userId'].max()+1 # Number of unique users\n",
    "num_items = ratings['movieId'].max()+1 # Number of unique ratings\n",
    "\n",
    "all_movieIds = ratings['movieId'].unique() # Array of movie indices\n",
    "\n",
    "model = NCF(num_users, num_items, train_ratings, test_ratings, all_movieIds)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a44a77c729e4f0bb04b9226aa4bb9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855d7ecf712f4db5a981df3ee79cc079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69991803a58b4c848c8f57ba22c4be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f018874108340409b571ad1e5d3a654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8caf0e541142d193c74c3bbc3338a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a860e91cd0cb4c8caa6a4b69cd95ae2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae94e31c871c44a3b80f400085fd1ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6006740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model by reloading a new random set of negative samples at each epoch\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=6, reload_dataloaders_every_epoch=True, progress_bar_refresh_rate=50, logger=True, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a5147bf9934a7c929a4537bde73c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04553c69c9f24a26b3b8037a55e7f56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.26267385482788086}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.26267385482788086}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Test error 8 dim, 5 batches, 512 batch size\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "torch.save(model.state_dict(), 'best_weights_model1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Recommender System\n",
    "\n",
    "The model produced a low test error which indicates that the learning process went quite well. To be more specific in how the model works, we can create a list of movies that a specific user would like to see and check whether this list includes the most recent movie that the user has actually seen. Thus, we generate a bundle of movies where the majority of the films consist of randomly picked ones that the user hasn't seen together with the most recent film that the user has seen. Then we run the model to see whether the model manages to pick the most recent film to the top 10 of the movies it has selected. \n",
    "\n",
    "This is what we presumed in the beginning that we are more likely to find only one or a few good movies which we would like to see if we would randomly go to a movie theater to see what movies are being projected. We don't need to see all the movies there, just one which we like is enough. \n",
    "\n",
    "We then repeat this process for all users and count the average of successess to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, ratings, test_ratings, all_movieIds):\n",
    "    \"\"\"Evaluates the model from a bundle of 100 movies which includes\n",
    "    one movie that the user has seen most recently and the others which\n",
    "    the user hasn't seen.\n",
    "    \n",
    "    The prediction comes from the forward method of the model and for the output\n",
    "    we use np.squeeze() to remove unnecessary dimensions from predicted labels\n",
    "    and detach().numpy() to get a NumPy array from a torch tensor.\n",
    "    \"\"\"\n",
    "    # Placeholder for correct hits\n",
    "    hits = []\n",
    "    # user-item pairs for testing\n",
    "    user_item_test_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
    "    # Dictionary of interacted items by each user\n",
    "    user_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "    \n",
    "    for (u, i) in tqdm(user_item_test_set):\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
    "        group_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        bundle_items = group_not_interacted + [i]\n",
    "        \n",
    "        predicted_labels = np.squeeze(model(torch.tensor([u]*100), torch.tensor(bundle_items)).detach().numpy())\n",
    "        \n",
    "        top10 = [bundle_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "        \n",
    "        if i in top10:\n",
    "            hits.append(1)\n",
    "        else:\n",
    "            hits.append(0)\n",
    "    \n",
    "    return np.average(hits)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7c109f40584adaaf11aa6f9daf4cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8138012371531037"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, ratings, test_ratings, all_movieIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results confirm the previous test result. When evaluating the model with our custom metric, the model produced a very good accuracy of over 81 % which means the model managed to find, by learning with 8 dimensional user and movie embeddings for 33650 users out of 41547 the specific movie the user rated most recently.\n",
    "\n",
    "It is thus reasonable to assume this model could find a list of movies where at least one or a few of the movies this particular user would enjoy and like to see. Furthermore, this same model could be easily transformed into recommendation of other items such as music, books, or any kind of other products or services that you can find online.\n",
    "\n",
    "Next we will be exploring two neural network models that give a list of recommended movies based on particular explicit user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering via Explicit User Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainder of the models, the learning will happen through explicit interactions from the user ratings and all the ratings will be treated equally, no mather how recently or far back in time a movie has been rated. This will make the learning process more difficult, as there will be less of training data and more of testing data, but also because now we need to predict the actual rating instead of a boolean yes or no.\n",
    "\n",
    "The splitting of the dataset more randomly can be argumented if we assume for example that taste and preferences of people take a long time to develop so that a sudden change is not very common or we should at least except the change to happen gradually through time. Moreover, some movies that are part of a series, for example the Marvel movies, might have a sequel or they continue from the first part, like in the Guardians of the Galaxy, but it dosn't really matter in which order you see these movies as they don't really reveal so much of the \"main\" plot so that the viewing experience would be ruined if you hadn't see the first one before the last one. This is actually true to many of the recently made movies, at least after the Millenium, which has been perhaps a decision taken by the production companies in order to accumulate as many people as possible to the cinemas; as even those people that haven't seen the previous movies of a particular series (e.g. James Bond, Jason Bourne, Mission Impossible, etc.) might be tempted to see the latest movie of the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from the data\n",
    "\n",
    "The learning will happen again through the embeddings, where the users and movies will first be encoded as integer indices and made into sets by first splitting with 80:20 ratio into training and testing sets, and then continued on with a 90:10 split into training and validation sets respectively.\n",
    "\n",
    "The predictions will be more difficult than before, as the test dataset is now larger and we are going to make predictions no matter when a rating was made which makes the calculations more difficult. For the model the dimensions of the vector embeddings will thus be increased and for the first model we will use the product to calculate the similarities between the users and the movies. The filling of the missing entries of the ratings will happen gradually again with the gradient descent algorithm. We will also normalize the ratings and include a bias term for the users and for the movies to incorporate for the bias that might arise when people give a rating that is too extreme (i.e. too generous or too negative), and to incorporate so that the movies would represent better themselves rather than the average of all the movies. So to start everything off, first we create a function that handles all the data the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    \"\"\"Prepares MovieLens PyTorch Dataset.\n",
    "    \n",
    "    The dataset is split into training, validating and testing sets. Separate functions\n",
    "    prepare each set after the split.\n",
    "    \n",
    "    Args:\n",
    "        ratings : Dataframe containing the movie ratings\n",
    "    \n",
    "    Returns:\n",
    "        Tensors of users, items, and labels for training, validating and testing\n",
    "    \"\"\"\n",
    "    def __init__(self, ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.train_data, self.val_data, self.test_data = self._setup(ratings)\n",
    "        self.train_users, self.train_items, self.train_labels = self.get_training_data(self.train_data)\n",
    "        self.val_users, self.val_items, self.val_labels = self.get_val_data(self.val_data)\n",
    "        self.test_users, self.test_items, self.test_labels = self.get_test_data(self.test_data)\n",
    "        self.n_users = len(ratings['userId'].unique())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_users\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_users[idx], self.train_items[idx], self.train_labels[idx]\n",
    "    \n",
    "    def _setup(self, ratings):\n",
    "        \n",
    "        # Mapping user indices\n",
    "        users_unique = ratings.userId.unique()\n",
    "        userid2idx = {x:u for u,x in enumerate(users_unique)}\n",
    "        ratings['user_id'] = ratings['userId'].map(userid2idx)\n",
    "    \n",
    "        # Mapping movie indices\n",
    "        movies_unique = ratings.movieId.unique()\n",
    "        movieid2idx = {x:i for i,x in enumerate(movies_unique)}\n",
    "        ratings['movie_id'] = ratings['movieId'].map(movieid2idx)\n",
    "        \n",
    "        X = ratings[['user_id', 'movie_id']].values\n",
    "        y = ratings['rating'].astype(np.float32)\n",
    "    \n",
    "        # Normalizing data\n",
    "        min_rating = min(ratings['rating'])\n",
    "        max_rating = max(ratings['rating'])\n",
    "        \n",
    "        y = ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "    \n",
    "        # Splitting data into training and testing sets\n",
    "        train_indices = int(0.8 * ratings.shape[0])\n",
    "        X_train = X[:train_indices]\n",
    "        y_train = y[:train_indices]\n",
    "        X_test = X[train_indices:]\n",
    "        y_test = y[train_indices:]\n",
    "        \n",
    "        test_users = X_test[:,0]\n",
    "        test_items = X_test[:,1]\n",
    "        test_labels = y_test\n",
    "        \n",
    "        # Splitting training data into training and validating sets\n",
    "        val_indices = int(0.9 * len(X_train))\n",
    "        X_val = X_train[val_indices:]\n",
    "        y_val = y_train[val_indices:]\n",
    "        X_train = X_train[:val_indices]\n",
    "        y_train = y_train[:val_indices]\n",
    "        \n",
    "        val_users = X_val[:,0]\n",
    "        val_items = X_val[:,1]\n",
    "        val_labels = y_val\n",
    "        \n",
    "        train_users = X_train[:,0]\n",
    "        train_items = X_train[:,1]\n",
    "        train_labels = y_train\n",
    "        \n",
    "        train_data = [train_users, train_items, train_labels]\n",
    "        val_data = [val_users, val_items, val_labels]\n",
    "        test_data = [test_users, test_items, test_labels]\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "               \n",
    "    def get_training_data(self, train_data):\n",
    "        users, items, labels = train_data\n",
    "        \n",
    "        return torch.LongTensor(users), torch.LongTensor(items), torch.FloatTensor(labels)\n",
    "     \n",
    "    def get_val_data(self, val_data):\n",
    "        users, items, labels = val_data\n",
    "        \n",
    "        return torch.LongTensor(users), torch.LongTensor(items), torch.FloatTensor(labels)\n",
    "    \n",
    "    def get_test_data(self, test_data):\n",
    "        users, items, labels = test_data\n",
    "        \n",
    "        return torch.LongTensor(users), torch.LongTensor(items), torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model \n",
    "\n",
    "When training deep neural networks, the learning rate is one of the most important hyper-parameters you can tune. It is often made to decay slowly as time goes by inorder to find the sweet spot and achieve best results through the learning process. However, the right rate can be difficult to find and takes a long time to fine-tune. One approach to find the right rate quicker is to use a Cyclical Learning Rate (CLR) that eliminates the need to experiment with different learning rates as the method lets the rate to cyclically vary between a boundary of values. \n",
    "\n",
    "We will create a CLR that follows a cosine annealing scheduler where we can choose from two options: either the rate acts like a wave in the ocean (i.e. the rate has a form of a rising and descending wave following the cosine function) or the learning rate is slowly decaying. The idea is that we start our search for the optimum parameters with a high learning rate and gradually decrease the rate with more iterations in order to stay at the local minimum and not accidentaly take a too large step and loose the sight of progress. In the first option, we repeatedly restart this process, as in the form of a warm restart, to bring the learning rate up again before gradually decreasing the rate till the end. This decaying learning rate, and also dropping the batch size to 32 will help our model to find more stable solution with each iteration. \n",
    "\n",
    "We are now trying to predict the actual explicit ratings that have a range from 0 to 5, so to control for the accuracy in the training process we will use the Mean Squared Error (MSE), that is the average of the squared differences between a set of values and predictions. This will measure the quality of the recommender as it incorporates both the variance - the spread of the estimates - and the bias - how far off the average estimated value is from the true value. Other accuracy methods include the Root Mean Squared Error (RMSE) which is the square root of the MSE and the Mean Absolute Error (MAE) which measures the average of the absolute differences between a set of values and predictions. All these metrics would work in a similar way, the differense being that the first two penalize large errors more heavily.\n",
    "\n",
    "Finally, to see how the model actually performs, we will make movie recommendations for some user and see what kind of movies the model recommends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLR based on cosine annealing\n",
    "\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \"\"\"A Cyclical Learning Rate based on cosine annealing that inherits\n",
    "    get_lr() from the PyTorch scheduler class.\n",
    "    \n",
    "    Research paper: Leslie N. Smith, (2017), \"Cyclical Learning Rates for\n",
    "    Training Neural Networks\", arXiv:1506.01186 \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        \"\"\"Returns a list of learning rates depending on the current training epoch.\n",
    "        \"\"\"\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "    \n",
    "def cosine_annealing(t_max, eta_min=0):\n",
    "        \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi * t / t_max)) /2\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Cosine annealing CLR with warm start\n",
    "\n",
    "ts = list(range(1000))\n",
    "y = [cosine_annealing(t_max=500, eta_min=0.0005)(t, 0.001) for t in ts]\n",
    "plt.title('Cosine Cyclical Learning Rate with Warm-Starting')\n",
    "plt.plot(ts, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Cosine annealing CLR with decaying learning rate\n",
    "\n",
    "ts = list(range(1000))\n",
    "y = [cosine_annealing(t_max=4000, eta_min=0.0005)(t, 0.001) for t in ts]\n",
    "plt.title('Cosine Cyclical Decaying Learning Rate')\n",
    "plt.plot(ts, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Matrix Factorization Model\n",
    "\n",
    "class NeuralMatrixFactorization(pl.LightningModule):\n",
    "    \"\"\"Neural Network that works like matrix factorization through the product\n",
    "       added with user and movie bias terms in order to calculate similarities between\n",
    "       users and movies\n",
    "    \n",
    "    Args:\n",
    "        num_users: Number of unique users (int)\n",
    "        num_items: Number of unique movies (int)\n",
    "        ratings: Dataframe containing the movie ratings\n",
    "    \n",
    "    Returns:\n",
    "        predicted ratings\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items, ratings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=25)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=25)\n",
    "        self.user_bias = nn.Embedding(num_embeddings=num_users, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=num_items, embedding_dim=1)\n",
    "        self.loss = nn.MSELoss(reduction='sum')\n",
    "        self.ratings = ratings\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        \n",
    "        dot = self.user_embedding(users) * self.item_embedding(items)\n",
    "        predictions = dot.sum(1) + self.user_bias(users).squeeze() + self.item_bias(items).squeeze()\n",
    "        predictions = nn.Sigmoid()(predictions)\n",
    "          \n",
    "        return predictions\n",
    "      \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        users, items, ratings = train_batch\n",
    "        predicted_labels = self(users, items)\n",
    "        loss = self.loss(predicted_labels.view(-1), ratings)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "        \n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        val_users, val_items, val_ratings = valid_batch\n",
    "        val_pred = self(val_users, val_items)\n",
    "        loss = self.loss(val_pred.view(-1), val_ratings)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'val_loss': loss, 'val_users': val_users.detach(), 'val_items': val_items.detach(), 'val_pred': val_pred.detach(), 'val_ratings': val_ratings.detach()}\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        test_users, test_items, test_ratings = test_batch\n",
    "        test_pred = self(test_users, test_items)\n",
    "        loss = self.loss(test_pred.view(-1), test_ratings)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {'test_loss':loss, 'test_users': test_users.detach(), 'test_items': test_items.detach(), 'test_pred': test_pred.detach(), 'test_ratings': test_ratings.detach()}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        scheduler = CyclicLR(optimizer, cosine_annealing(t_max=4000, eta_min=0.0005))\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralMatrixFactorization(\n",
       "  (user_embedding): Embedding(138491, 25)\n",
       "  (item_embedding): Embedding(131171, 25)\n",
       "  (user_bias): Embedding(138491, 1)\n",
       "  (item_bias): Embedding(131171, 1)\n",
       "  (loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model\n",
    "\n",
    "tb_logger = TensorBoardLogger('tb_logger', name='NeuralMatrixFactorization')\n",
    "\n",
    "num_users = ratings['userId'].max()+1 # Number of unique users in the whole dataset\n",
    "num_items = ratings['movieId'].max()+1 # Number of unique ratings in the whole dataset\n",
    "\n",
    "model_2 = NeuralMatrixFactorization(num_users, num_items, ratings)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8394d4ea16f4cf598b22ba932aedf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=31, reload_dataloaders_every_epoch=False, progress_bar_refresh_rate=50, logger=tb_logger, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)], checkpoint_callback=False)\n",
    "trainer.fit(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd565b0cb1b44f793a8bab784f1b0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.18592053651809692}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.18592053651809692}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer with dim 25, 30 epochs, 32 batch size\n",
    "\n",
    "trainer.test(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "torch.save(model_2.state_dict(), 'best_weights_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Recommender System\n",
    "\n",
    "We trained the model for 30 epochs, and the learning process went well as the model produced a very low test error of 0.186 from the ratings it hadn't seen before. So now we are ready to evaluate how the model actually performs. For this, we will create a list of recommended movies that a user hasn't seen before based on a few highly rated movies the user has seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation(model, ratings, movies):\n",
    "    \"\"\"Creates a list of recommended movies that the user hasn't seen before based\n",
    "    on the learned embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_id = ratings.userId.sample(1).iloc[0]\n",
    "    movies_watched_by_user = ratings[ratings.userId == user_id]\n",
    "    movies_not_watched = ratings[~ratings[\"movieId\"].isin(movies_watched_by_user.movieId.values)][\"movieId\"]\n",
    "    movie_ids = ratings[\"movieId\"].unique().tolist()\n",
    "    movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "    movies_not_watched = list(set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))\n",
    "    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "    \n",
    "    user_ids = ratings[\"userId\"].unique().tolist()\n",
    "    user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "    user_encoder = user2user_encoded.get(user_id)\n",
    "    \n",
    "    user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), movies_not_watched))\n",
    "    predicted_ratings = model(torch.LongTensor(user_movie_array[:,0]), torch.LongTensor(user_movie_array[:,1]))\n",
    "    predictions =  np.squeeze(predicted_ratings.detach().numpy())\n",
    "    top_ratings_indices = predictions.argsort()[-10:][::-1]\n",
    "    movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "    recommended_movie_ids = [movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices]\n",
    "    \n",
    "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "    print(\"====\" * 10)\n",
    "    print(\"Movies with high ratings from user\")\n",
    "    print(\"----\" * 9)\n",
    "    \n",
    "    top_movies_user = (movies_watched_by_user.sort_values(by=\"rating\", ascending=False).head(5).movieId.values)\n",
    "    movie_df_rows = movies[movies[\"movieId\"].isin(top_movies_user)]\n",
    "    \n",
    "    for row in movie_df_rows.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "\n",
    "    print(\"----\" * 7)\n",
    "    print(\"Top 10 movie recommendations\")\n",
    "    print(\"----\" * 7)\n",
    "    \n",
    "    recommended_movies = movies[movies[\"movieId\"].isin(recommended_movie_ids)]\n",
    "    for row in recommended_movies.itertuples():\n",
    "        print(row.title, \":\", row.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 12767\n",
      "========================================\n",
      "Movies with high ratings from user\n",
      "------------------------------------\n",
      "Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983) : Documentary\n",
      "Hud (1963) : Drama|Western\n",
      "Hustler, The (1961) : Drama\n",
      "Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001) : Comedy|Romance\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) : Adventure|Fantasy\n",
      "----------------------------\n",
      "Top 10 movie recommendations\n",
      "----------------------------\n",
      "Roman Holiday (1953) : Comedy|Drama|Romance\n",
      "Purple Rose of Cairo, The (1985) : Comedy|Drama|Fantasy|Romance\n",
      "Little Big Man (1970) : Western\n",
      "Far and Away (1992) : Adventure|Drama|Romance\n",
      "Inherit the Wind (1960) : Drama\n",
      "Joe Dirt (2001) : Adventure|Comedy|Mystery|Romance\n",
      "Bourne Identity, The (2002) : Action|Mystery|Thriller\n",
      "City of God (Cidade de Deus) (2002) : Action|Adventure|Crime|Drama|Thriller\n",
      "How to Train Your Dragon (2010) : Adventure|Animation|Children|Fantasy|IMAX\n",
      "Frozen (2013) : Adventure|Animation|Comedy|Fantasy|Musical|Romance\n"
     ]
    }
   ],
   "source": [
    "make_recommendation(model_2, ratings, movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We picked a random user who to give recommendations, and we can see from the previous high ratings of this particular pick that the task will be quite challenging, as the movies have a timspan of 40 years, from the 1960s to 2000s, and all five movies come from a complitely different genre; a documentary, a western, a drama, a romantic comedy, and as a last pick an adventure fantasy.\n",
    "\n",
    "The model recommendations seemed to be up to the task however and produced very good results. They also have a wide timespan, ranging from all the way from the 1950s to more recent 2010s. A quick search shows that most of the movies have gotten quite good reviews from the critics and from people in general. The only movie that has gotten really mixed positive and negative reviews is Joe Dirt. The genres seem to be also matching pretty well, only a documentary is missing, but we still have a large and wide selection of movies that could attrack younger or older crowds, and if we think similarly than before, that a person will probably be interested of just one or a few movies offered, the recommendations seem to be doing just that.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Movie Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed quite well, but we also gave the direction where to go, so this time, we will only provide the model architecture and the embeddings, and let the algorithm decide on itself how to learn and optimize the right parameters.\n",
    "\n",
    "The model uses the same cyclical learning rate and embeddings as before, but we will increase the dimensions of the embeddings a bit and include a number of fully connected layers and dropout layers. The model archutecture is built in a flexible way that lets you to adjust how many connected or dropout layers you want to have, and also what kind of dropout rate the dropout layers should have. Here, the dropout layers stand for layers that randomly drop some of the parameters going through the network, making the model less certain of taking a particular direction and also helping the model to not overfit so easily.\n",
    "\n",
    "Next, we create the model class, initiate the training routine, and evaluate the results with the test error and with the predicted movies the model comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class for the model\n",
    "\n",
    "class NeuralNetworkMovieRecommender(pl.LightningModule):\n",
    "    \"\"\"The idea for the model comes from Ilia Zaitsev\n",
    "    https://github.com/devforfu/pytorch_playground/blob/master/movielens.ipynb\n",
    "    \n",
    "    The generator enables to create an architecture where the number of \n",
    "    fully connected hidden layers and dropout layers as well as the\n",
    "    rate of the dropout layers are all adjustable. The weights\n",
    "    of the hidden layers as well as the emebedding layers are initialized\n",
    "    from a uniform distribution.\n",
    "    \n",
    "    Args:\n",
    "        num_users: Number of unique users (int)\n",
    "        num_items: Number of unique movies (int)\n",
    "        hidden: Numer of units in hidden layers added as a list\n",
    "        dropouts: Dropout layer rate added as a list\n",
    "        ratings: Dataframe containing the movie ratings for training\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, hidden=10, dropouts=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        def get_list(n):\n",
    "            if isinstance(n, (int, float)):\n",
    "                return [n]\n",
    "            elif hasattr(n, '__iter__'):\n",
    "                return list(n)\n",
    "        \n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def generate_layers(num_in):\n",
    "            \"\"\"Generator that creates hidden and dropout layers.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "            for num_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(num_in, num_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                num_in = num_out\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=50)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=50)\n",
    "        self.drop = nn.Dropout(0.02)\n",
    "        self.hidden = nn.Sequential(*list(generate_layers(50 * 2)))\n",
    "        self.output = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        self.loss = nn.MSELoss(reduction='sum')\n",
    "        self.ratings = ratings\n",
    "        \n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "        \n",
    "        x = torch.cat([user_embedded, item_embedded], dim=1)\n",
    "        x = self.drop(x)\n",
    "        x = self.hidden(x)\n",
    "        \n",
    "        prediction = nn.Sigmoid()(self.output(x))\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def _init(self):\n",
    "        \"\"\"Setup for initial values for embeddings and hidden layers.\n",
    "        \"\"\"\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "        \n",
    "        self.user_embedding.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.item_embedding.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.output)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        users, items, ratings = train_batch\n",
    "        predicted_labels = self(users, items)\n",
    "        loss = self.loss(predicted_labels.view(-1), ratings)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "        \n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        val_users, val_items, val_ratings = valid_batch\n",
    "        val_pred = self(val_users, val_items)\n",
    "        loss = self.loss(val_pred.view(-1), val_ratings)\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'val_loss': loss, 'val_users': val_users.detach(), 'val_items': val_items.detach(), 'val_pred': val_pred.detach(), 'val_ratings': val_ratings.detach()}\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        test_users, test_items, test_ratings = test_batch\n",
    "        test_pred = self(test_users, test_items)\n",
    "        loss = self.loss(test_pred.view(-1), test_ratings)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {'test_loss':loss, 'test_users': test_users.detach(), 'test_items': test_items.detach(), 'test_pred': test_pred.detach(), 'test_ratings': test_ratings.detach()}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        scheduler = CyclicLR(optimizer, cosine_annealing(t_max=4000, eta_min=0.0005))\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(MovieLensDataset(self.ratings), batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkMovieRecommender(\n",
       "  (user_embedding): Embedding(138491, 50)\n",
       "  (item_embedding): Embedding(131171, 50)\n",
       "  (drop): Dropout(p=0.02, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model\n",
    "\n",
    "num_users = ratings['userId'].max()+1 # Number of unique users in the whole dataset\n",
    "num_items = ratings['movieId'].max()+1 # Number of unique ratings in the whole dataset\n",
    "\n",
    "tb_logger = TensorBoardLogger('tb_logger', name='NeuralNetworkMovieRecommender')\n",
    "\n",
    "model_3 = NeuralNetworkMovieRecommender(num_users, num_items, ratings)\n",
    "\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ab6595d0b34ee696608b09f9887e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=31, reload_dataloaders_every_epoch=False, progress_bar_refresh_rate=50, logger=tb_logger, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)], checkpoint_callback=False)\n",
    "trainer.fit(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fff52691d743dda04bd032b86d7c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.7785917520523071}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7785917520523071}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainer with 50 dim, 32 batch size, 30 epochs\n",
    "\n",
    "trainer.test(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "torch.save(model_3.state_dict(), 'best_weights_model3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for 30 epochs we get a test error result of around 0.779 which is quite low but not as good as before. We will again make some recommendations to see how the model actually performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 761\n",
      "========================================\n",
      "Movies with high ratings from user\n",
      "------------------------------------\n",
      "Braveheart (1995) : Action|Drama|War\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Apocalypse Now (1979) : Action|Drama|War\n",
      "L.A. Confidential (1997) : Crime|Film-Noir|Mystery|Thriller\n",
      "Pleasantville (1998) : Comedy|Drama|Fantasy\n",
      "----------------------------\n",
      "Top 10 movie recommendations\n",
      "----------------------------\n",
      "Man Who Would Be King, The (1975) : Adventure|Drama\n",
      "You Can't Take It with You (1938) : Comedy|Romance\n",
      "Days of Heaven (1978) : Drama\n",
      "Inherit the Wind (1960) : Drama\n",
      "Auntie Mame (1958) : Comedy|Drama\n",
      "The Big Sleep (1978) : Thriller\n",
      "2 Days in Paris (2007) : Comedy|Drama|Romance\n",
      "RocknRolla (2008) : Action|Crime\n",
      "Last Circus, The (Balada triste de trompeta) (Sad Trumpet Ballad, A) (2010) : Comedy|Drama|War\n",
      "Louis C.K.: Hilarious (2010) : Comedy\n"
     ]
    }
   ],
   "source": [
    "make_recommendation(model_3, ratings, movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick again a random user and see a list of five movies the user has enjoyed in the past. This time we have a selection of movies from the end of the 1970s until the end of 1990s, where we have two action style drama-war movies, one Film-Noir type mystery-crime-thriller, one crime-drama and one comedy that has some drama and fantasy blended together. I have personally seen the four first ones on the list which I enjoyed a lot and which I think stands as classic movies in their respective genres so I am really looking forward what the recommendations this time will show.\n",
    "\n",
    "A quick glance at the recommendations show the timespan going from the end of the 1930s all the way to 2010s, making again a surprisingly wide selection through the years. Why did the model choose a wide timespan like this; makes me think this could be either quite an amazing selection or just a random collection of movies. I do not know most the recommended movies, but a more careful search shows that most of the recommended movies have actually gotten quite good reviews from the critics and people in general. However, I can't help myself thinking that it is quite a gamble to propose movies from the 1930s and 1950s for someone who indicates liking a list of movies from the 70s till the 90s. A black and white old movie is not quite the same as the movies we have now, so this time I am not so convinced these recommendations could actually work for the selected user, although I have to say there are two movies which I have seen before from the recommendations (RocknRolla and Louis C.K.: Hilarious) which I also liked, perhaps not as much the four movies before, but if I wouldn't hadn't seen them, I would have put them on my watch list as I enjoy Guy Ritchie's movies and I think Louis C.K. is actually quite funny. So overall, if we again presume a person should enjoy at least one or a few movies from the list, then this model passed the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization with Singular Value Decomposition\n",
    "\n",
    "For the final model, we will use matrix factorization with Singular Value Decomposition (SVD) to compare with the predictions we got from the previous models. Compared to the other previous models, we don't need to wait for the model to train and learn anything as we only need to perform some linear algebra. Moreover, matrix factorization is the breaking down of one matrix into a product of multiple matrices which can be done SVD which is an algorithm that decomposes a matrix $R$ into the best lower rank approximation of the original matrix $R$. Mathematically, it decomposes $R$ into two unitary matrices and a diagonal matrix:\n",
    "\n",
    "$$\\begin{equation} R = U\\Sigma V^{T} \\end{equation}$$\n",
    "\n",
    "where $R$ is user ratings matrix, $U$ is the user features matrix that describes user preferences on the movies, $\\Sigma$ is the diagonal matrix of singular values (i.e. weights), and $V^{T}$ is the movie features matrix that indicates how relevant each feature is to each movie. \n",
    "\n",
    "To get the lower rank approximation we take the top $k$ features which are the most important to underly taste and preference vectors.\n",
    "\n",
    "First we will create a user-item matrix and fill the missing values with zeros, and then normalize the ratings according to each user by substracting the mean of each user from the rating. After creating predicted ratings with the SVD, we recreate the two predictions we created before and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>131017</th>\n",
       "      <th>131019</th>\n",
       "      <th>131027</th>\n",
       "      <th>131080</th>\n",
       "      <th>131110</th>\n",
       "      <th>131158</th>\n",
       "      <th>131164</th>\n",
       "      <th>131166</th>\n",
       "      <th>131168</th>\n",
       "      <th>131170</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           0.0     3.5     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0     0.0     0.0     0.0     3.0     0.0     0.0   \n",
       "5           0.0     3.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "24          4.0     0.0     0.0     0.0     2.0     4.0     3.0     0.0   \n",
       "32          0.0     0.0     0.0     0.0     0.0     3.0     0.0     0.0   \n",
       "\n",
       "movieId  9       10      ...  131017  131019  131027  131080  131110  131158  \\\n",
       "userId                   ...                                                   \n",
       "1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     4.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "24          0.0     3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "32          0.0     3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  131164  131166  131168  131170  \n",
       "userId                                   \n",
       "1           0.0     0.0     0.0     0.0  \n",
       "4           0.0     0.0     0.0     0.0  \n",
       "5           0.0     0.0     0.0     0.0  \n",
       "24          0.0     0.0     0.0     0.0  \n",
       "32          0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 22836 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating user-item matrix\n",
    "\n",
    "ratings_svd = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "ratings_svd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41547, 22836)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the ratings with the mean\n",
    "\n",
    "R = ratings_svd.to_numpy()\n",
    "user_ratings_mean = np.mean(R, axis=1)\n",
    "R_scaled = R - user_ratings_mean.reshape(-1,1)\n",
    "R_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition with 50 features\n",
    "\n",
    "U, sigma, Vt = svds(R_scaled, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41547, 22836)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions with dot-product and adding the mean back for each user\n",
    "\n",
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1,1)\n",
    "all_user_predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe from the predictions\n",
    "\n",
    "preds_df = pd.DataFrame(all_user_predicted_ratings, columns=ratings_svd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(predictions_df, userID, movies_df, original_ratings_df, num_recommendations):\n",
    "    \"\"\"Makes a list of recommendated movies that the user hasn't seen before\n",
    "    \"\"\"\n",
    "    user_row_number = userID-1  \n",
    "    sorted_user_predictions = predictions_df.iloc[user_row_number].sort_values(ascending=False)\n",
    "      \n",
    "    user_data = original_ratings_df[original_ratings_df.userId == (userID)]\n",
    "    user_full = (user_data.merge(movies_df, how = 'left', left_on = 'movieId', right_on = 'movieId').\n",
    "                     sort_values(['rating'], ascending=False)\n",
    "                 ).head(5)\n",
    "    \n",
    "    recommendations = (movies_df[~movies_df['movieId'].isin(user_full['movieId'])].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "               left_on = 'movieId',\n",
    "               right_on = 'movieId').\n",
    "         rename(columns = {user_row_number: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).\n",
    "                       iloc[:num_recommendations+1, :-1]\n",
    "                      )  \n",
    "\n",
    "    print(\"Showing recommendations for user: {}\".format(userID))\n",
    "    print(\"====\" * 10)\n",
    "    print(\"Movies with high ratings from user\")\n",
    "    print(\"----\" * 9)\n",
    "    \n",
    "    movie_df_rows = movies_df[movies_df[\"movieId\"].isin(user_full.movieId)]\n",
    "    for row in movie_df_rows.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "\n",
    "    print(\"----\" * 7)\n",
    "    print(\"Top 10 movie recommendations\")\n",
    "    print(\"----\" * 7)\n",
    "    \n",
    "    recommended_movies = movies_df[movies_df[\"movieId\"].isin(recommendations.movieId)]\n",
    "    \n",
    "    for row in recommended_movies.itertuples():\n",
    "        print(row.title, \":\", row.genres)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 12767\n",
      "========================================\n",
      "Movies with high ratings from user\n",
      "------------------------------------\n",
      "Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983) : Documentary\n",
      "Hud (1963) : Drama|Western\n",
      "Hustler, The (1961) : Drama\n",
      "Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001) : Comedy|Romance\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) : Adventure|Fantasy\n",
      "----------------------------\n",
      "Top 10 movie recommendations\n",
      "----------------------------\n",
      "Heat (1995) : Action|Crime|Thriller\n",
      "Seven (a.k.a. Se7en) (1995) : Mystery|Thriller\n",
      "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
      "Clerks (1994) : Comedy\n",
      "Pulp Fiction (1994) : Comedy|Crime|Drama|Thriller\n",
      "Godfather, The (1972) : Crime|Drama\n",
      "Reservoir Dogs (1992) : Crime|Mystery|Thriller\n",
      "Goodfellas (1990) : Crime|Drama\n",
      "Godfather: Part II, The (1974) : Crime|Drama\n",
      "American Pie (1999) : Comedy|Romance\n",
      "Fight Club (1999) : Action|Crime|Drama|Thriller\n"
     ]
    }
   ],
   "source": [
    "recommend_movies(preds_df, 12767, movies_df, ratings, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 761\n",
      "========================================\n",
      "Movies with high ratings from user\n",
      "------------------------------------\n",
      "Braveheart (1995) : Action|Drama|War\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Apocalypse Now (1979) : Action|Drama|War\n",
      "L.A. Confidential (1997) : Crime|Film-Noir|Mystery|Thriller\n",
      "Pleasantville (1998) : Comedy|Drama|Fantasy\n",
      "----------------------------\n",
      "Top 10 movie recommendations\n",
      "----------------------------\n",
      "Apollo 13 (1995) : Adventure|Drama|IMAX\n",
      "Crimson Tide (1995) : Drama|Thriller|War\n",
      "Die Hard: With a Vengeance (1995) : Action|Crime|Thriller\n",
      "Net, The (1995) : Action|Crime|Thriller\n",
      "Outbreak (1995) : Action|Drama|Sci-Fi|Thriller\n",
      "While You Were Sleeping (1995) : Comedy|Romance\n",
      "Clear and Present Danger (1994) : Action|Crime|Drama|Thriller\n",
      "True Lies (1994) : Action|Adventure|Comedy|Romance|Thriller\n",
      "Cliffhanger (1993) : Action|Adventure|Thriller\n",
      "Dances with Wolves (1990) : Adventure|Drama|Western\n",
      "Batman (1989) : Action|Crime|Thriller\n"
     ]
    }
   ],
   "source": [
    "recommend_movies(preds_df, 761, movies_df, ratings, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same users as before and the list of 5 movies these users have liked in the past, but this time we can immediately see a big difference in the recommendations compared to what they were previously. Now the timespan of the movies is much tightly packed than previously, ranging from the 1970s till the 1990s for the first user, and from the 1980s till the 1990s for the second user. For the latter user this perhaps would be a more accurate selection of movies, as it more reflects what the user has also liked before, but for the first user, personally I would have liked to see a more wider selection between the years than a concentration like this one, although this time, the recommended movies have Oscar winners and movies that can be said to define their genres and the time these movies came out, like the Godfather, Pulp Fiction or Dances with Wolves. These movies are actually really good and definitely worth seeing if you haven't seen them before so we can say the model produced really good recommendations. However, the recommendations do come with a caveat, and that is the more narrow timespan and one-type genre the algorithm seems to produce, as we can see most of the first list is of crime movies and the second of action movies. Personally, I have seen almost every movie on the first list, except one (Clerks) and also most the movies from the second list, so for me at least, even though these lists perhaps produced a more accurate selection of movies regarding each user, there is some randomness in the form of \"surprises\" that is missing, which I did enjoy to see on the other previous lists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
